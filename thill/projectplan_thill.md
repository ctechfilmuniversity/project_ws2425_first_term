
# **God complex - Project plan**

---

### **Motivation**

#### **Personal Motivation**  
The "God Complex" project stems from my passion for exploring the intersection of music, visuals, and interactivity. As a music producer with a growing interest in interactive media, I find it fascinating to create immersive experiences where audiences can influence the narrative or atmosphere directly. This project allows me to challenge traditional notions of passive consumption by giving visitors the ability to "play God" and shape the installation’s audiovisual elements.  

#### **Contextual Information**  
The project draws inspiration from various multimedia installations and immersive experiences, including works by artists like Iglooghost, Olafur Eliasson, and Max Cooper, who blend music, visuals, and technology. These projects demonstrate how interactivity can enhance audience engagement. My work will add to this discourse by addressing the metaphoric implications of humanity’s insatiable desire to control nature and the present, a theme particularly relevant in our age of climate and technological challenges.  

#### **Visual Style**

This project can potentially be thought of as a continuation of an earlier project I created called Subsurface, a 3D animated music video. Stylistically, I aim to draw inspiration from the aesthetic choices I made in that project. Below are some frames from Subsurface to illustrate its visual style.

However, this is not a strict requirement—I am also open to exploring a new visual style that might better suit the themes and interactivity of God Complex.

<img src=img/01.png alt="alt text" width="400">
<img src=img/02.png alt="alt text" width="400">
<img src=img/03.png alt="alt text" width="400">

---

### **Project Details**

#### **Description**  
"God Complex" is an interactive audiovisual installation that gives visitors the power to influence both the music and visuals of a digital environment. The installation includes:  

1. **Music Component**:  
   Visitors can alter harmonic modes (e.g., minor, major, Phrygian, pentatonic) via a MIDI controller. A prototype in Ableton Live has already demonstrated the feasibility of this interaction. The goal is to make the musical changes deeply tied to the visuals, creating an atmosphere where sound and image influence each other harmoniously.  

2. **Visual Component**:  
   Using Unreal Engine, the installation will depict a dynamic landscape where parameters like vegetation density, weather, and sun position change based on user input. For instance, a minor melody might trigger rain, whereas a major mode might increase sunlight intensity.  

3. **Interaction**:  
   A MIDI controller allows visitors to adjust one parameter each for music and visuals. If time permits, I plan to expand this system to include additional scenes or create a custom Arduino-based controller for a more tactile experience.  

#### **Categorisation**  
The project spans several categories:  

- **Creative / Artistic Development**: The installation merges music and visuals into a cohesive artistic statement.  
- **Narrative Development**: The metaphor of "playing God" adds depth, encouraging reflection on humanity's desire to control nature.  
- **Audio-visual Design**: The project features a tight integration of sound design and dynamic visuals.  
- **Software Development**: Includes MIDI mapping, Unreal Engine scripting, and Max for Live integration.  
- **Research / Experimentation**: Testing how users respond to different interactive elements, ensuring the system feels intuitive and engaging.  

#### **System Diagram / Technical Setup / Tech Stack**  
The setup includes:  
- **Ableton Live & Max for Live**: For music production and interactive control of harmonic modes.  
- **Unreal Engine**: For real-time rendering of visual landscapes and interactive elements.  
- **MIDI Controller**: To provide intuitive user interaction.  
- **Potential Arduino Integration**: If time allows, to create a custom hardware controller.  

---

### **Unique Selling Point**  
This project stands out by merging interactivity with a meaningful metaphor. It critiques humanity’s unquenchable thirst for control, expressed through the ability to influence a digital world. The unique integration of harmonic modes with dynamic visuals adds artistic depth, setting it apart from typical audiovisual installations.  

---

### **Expected Results**

#### **Baseline Solution**  
The installation will feature one dynamic visual projection linked to a single track, with visitors able to modify one music and one visual parameter through the MIDI controller.  

#### **Best Possible Solution**  
If progress exceeds expectations, I aim to:  
1. Add more parameters for interaction.  
2. Include a second scene and track.  
3. Develop a custom controller using Arduino and Max for Live.  

---

### **Vision and Future Work**  
In the long term, I envision expanding the installation into a multi-room environment, closer to my original "Sonic Rooms" concept. This could involve collaborations with other artists, more complex interactivity, and a broader exploration of the "God Complex" theme.  

---

### **Challenge of Your Comfort Zone**  
This project challenges me in several ways:  
- Learning Unreal Engine, as I’m more familiar with Cinema4D.  
- Developing interactive systems using Max for Live and potentially Arduino.  
- Managing the technical complexities of real-time audiovisual integration.  
I expect the Unreal Engine setup to be the most difficult aspect, particularly programming the dynamic visuals.  

---

### **Work Plan**
#### **Timeline Until the Deadline**  
The project will be completed in 10 weeks, divided into the following work packages:  

1. **Week 1**: Learn Unreal Engine basics and finalise the Ableton prototype.  
2. **Week 2**: Start building the visual scene in Unreal Engine and develop the first live track.  
3. **Weeks 3-4**: Complete the first blueprint setup and add extra Unreal Engine assets.  
4. **Week 5**: Develop the MIDI controller setup for interactivity.  
5. **Week 6**: Expand the conceptual narrative and assemble the minimal setup.  
6. **Week 7**: Debugging and problem-solving, plus UI/UX refinements.  
7. **Week 8**: Implement final changes to audio-visual integration.  
8. **Week 9**: Overhead for testing and adjustments.  
9. **Week 10**: Final preparations and documentation.  

Check out this [link](https://coal-flute-cca.notion.site/1741d87be90f80d08f4fca90f6188ef9?v=b6141caf936b4d94882c18acffe13dae&pvs=4) to see my actual Work Plan + Live documentation, which provides an up-to-date and comprehensive overview of the project's progress.

Each time slot represents the time frame in which I plan to complete a particular task. As such, they do not represent full working days, and as long as I manage to work on time, I will try to keep my weekends free for some recovery time. From the 1st of March I plan to implement the last changes. In addition, I have set an overhead time of 6 days. In the ideal case, if I'm able to finish a task earlier than planned, I can drag everything past that date to the left and increase the overhead time. On this page I can switch between the timeline view and the gallery view, which gives me a better overview of my documentation. In the timeline view, the total number of hours spent on the project is displayed in the last row.
#### **Milestones**  
- Prototype of the MIDI controller and visual interactivity: **Week 2**  
- First functional scene with music and visuals: **Week 5**  
- Fully integrated system ready for testing: **Week 8**  

